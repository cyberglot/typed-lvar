\documentclass[main.tex]{subfiles}
\begin{document}

\section{Introduction}

% \todo{Why are LVars important?}
% \todo{Introduce variants of running example which error or get stuck.}
% \todo{Why is typing LVars important?}
% \todo{What are our contributions?}

Parallel programming presents itself as a challenge; it usually requires a deterministic execution, \ie the programmer expects to observe an equivalent outcome from her program in the parallel and in the sequential setting. Pure functional programs can be trivially parallelised (meaning, executed in parallel) while maintaining determinism. It can be achieved by evaluating every argument within a function call:

\begin{lstlisting}[language=Haskell]
toPairs x y = (x, y)
f = proj$_1$ (toPairs, id)
a = expensiveComputation
b = 6 + 1

f a b
\end{lstlisting}

The main problem with effectful computations is that they cannot be modelled as a commutative structure. As a general rule, all effectful computations must follow a sequential framework that precludes parallel evaluation. The sole purpose of parallel programming is to make code run faster, and, historically, parallel programming has been done leveraging concurrent programming and shared mutable state. However, only parallel evaluation and parallel state are required. Parallel state is required to synchronise different computations without making all interactions with state sequential. LVars, introduced by Kuper \ref{kuper15}, provide the necessary framework for parallel state. In a simplistic view, LVars require update to be monotonic according to a (join, semi) lattice and read to follow a pre-defined set of values. With that, LVars guarantee all parallel state computations are deterministic.

\paragraph{What are LVars, really?} LVars are shared monotonic data structures for guaranteed-deterministic parallel programming. The underlying idea of LVars is that values under an order relation enable computations to be interleaved as will: information is partially ordered and can only grow within the structure, but never shrink. Earlier works on LVars have introduced two complementary calculi: $\lambda_{\text{LVar}}$ and $\lambda_{\text{LVish}}$. The $\lambda_{\text{LVar}}$ calculus comprises only the basic LVar operations' semantics and cannot encode negative information. As a result, algorithms that require \textit{absent} information in order to proceed cannot be encoded. On the other hand, the $\lambda_{\text{LVish}}$ calculus is a more algorithmic-expressive version of the $\lambda_{\text{LVar}}$ calculus featuring data structure freezing and event handlers.

We introduce the concepts behind LVars by example, at a higher level. Let us start by defining a lattice to work on a singleton set containing values from the natural numbers set, $\mathbb{N}$, where
\begin{itemize}
\item $\bot$ is defined as $\varnothing$;
\item and the partial order relation is the subset relation $\subseteq$.
\end{itemize}

\begin{lstlisting}[language=Haskell]
program : LVar {$\mathbb{N}$}
program = do
  l <- new
  put {6} l
  x <- get [{5}, {7}] l
  return x
\end{lstlisting}

We have defined a store that is created empty and can only be written to once. In other words, we have built an IVar using the semantics of LVars. In the code below, we define a computation \inhs{program} of type \inhs{LVar $\{\mathbb{N}\}$} that creates an LVar, puts \inhs{$\{6\}$} to it and gets two values, \inhs{$\{5\}$} and \inhs{$\{7\}$}.

Yet differently from traditional IVars, LVar-based IVars allows multiple \inhs{put}s of a value $v_2$ if it occurs before the current value $v_1$, meaning that $v_1 \sqsubseteq v_2$ yields $v_1$.

\end{document}

%%% Local Variables:
%%% TeX-master: "main"
%%% End:
